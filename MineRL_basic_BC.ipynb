{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxwl_yG1qhR7"
      },
      "source": [
        "<div style=\"text-align: center\">\n",
        "  <img src=\"https://github.com/KarolisRam/MineRL2021-Intro-baselines/blob/main/img/colab_banner.png?raw=true\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_BGlQwngccr"
      },
      "source": [
        "# Introduction\n",
        "This notebook contains the Behavioural Cloning baselines for the Research track of the [MineRL 2021](https://minerl.io/) competition. To run it you will need to enable GPU by going to `Runtime -> Change runtime type` and selecting GPU from the drop down list.\n",
        "\n",
        "These baselines differ slightly from the standalone version of these baselines on github - the DATA_SAMPLES parameter is set to 400,000 instead of the default 1,000,000. This is done to fit into the RAM limits of Colab.\n",
        "\n",
        "To train the agent using the obfuscated action space we first discretize the action space using KMeans clustering. We then train the agent using Behavioural cloning. The training takes 10-15 mins.\n",
        "\n",
        "You can find more details about the obfuscation here:  \n",
        "[K-means exploration](https://minerl.io/docs/tutorials/k-means.html)\n",
        "\n",
        "Also see the in-depth analysis of the obfuscation and the KMeans approach done by one of the teams in the 2020 competition:\n",
        "\n",
        "[Obfuscation and KMeans analysis](https://github.com/GJuceviciute/MineRL-2020)\n",
        "\n",
        "Please note that any attempt to work with the obfuscated state and action spaces should be general and work with a different dataset or even a completely new environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysSTXmT3YUeF"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HTScYNljgXv"
      },
      "source": [
        "%%capture\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa\n",
        "!sudo apt-get purge openjdk-*\n",
        "!sudo apt-get install openjdk-8-jdk\n",
        "!sudo apt-get install xvfb xserver-xephyr vnc4server python-opengl ffmpeg"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh6gb3UWjT3p",
        "outputId": "37fe054c-d935-402c-b2a7-4fda28abf26a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#%%capture\n",
        "!pip install --upgrade minerl\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install pytorch\n",
        "!pip install scikit-learn\n",
        "!pip install -U colabgymrender"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: minerl in /usr/local/lib/python3.8/dist-packages (0.4.4)\n",
            "Requirement already satisfied: lxml>=4.3.3 in /usr/local/lib/python3.8/dist-packages (from minerl) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from minerl) (1.21.6)\n",
            "Requirement already satisfied: ipython>=7.5.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (7.9.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from minerl) (4.6.0.66)\n",
            "Requirement already satisfied: xmltodict==0.12.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (0.12.0)\n",
            "Requirement already satisfied: bullet in /usr/local/lib/python3.8/dist-packages (from minerl) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.8/dist-packages (from minerl) (2.11.3)\n",
            "Requirement already satisfied: pillow>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (9.4.0)\n",
            "Requirement already satisfied: coloredlogs>=10.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from minerl) (3.9.0)\n",
            "Requirement already satisfied: daemoniker>=0.2.3 in /usr/local/lib/python3.8/dist-packages (from minerl) (0.2.3)\n",
            "Requirement already satisfied: gym<0.20,>=0.13.1 in /usr/local/lib/python3.8/dist-packages (from minerl) (0.19.0)\n",
            "Requirement already satisfied: getch>=1.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (1.0)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.8/dist-packages (from minerl) (4.64.1)\n",
            "Requirement already satisfied: simple-term-menu in /usr/local/lib/python3.8/dist-packages (from minerl) (1.6.0)\n",
            "Requirement already satisfied: Pyro4>=4.76 in /usr/local/lib/python3.8/dist-packages (from minerl) (4.82)\n",
            "Requirement already satisfied: dill>=0.3.1.1 in /usr/local/lib/python3.8/dist-packages (from minerl) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (2.25.1)\n",
            "Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.8/dist-packages (from minerl) (5.9.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from minerl) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=49.2.0 in /usr/local/lib/python3.8/dist-packages (from minerl) (57.4.0)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from minerl) (0.5.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from minerl) (3.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.8/dist-packages (from coloredlogs>=10.0->minerl) (10.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym<0.20,>=0.13.1->minerl) (1.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (0.18.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.5.0->minerl) (5.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.11.2->minerl) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->minerl) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->minerl) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->minerl) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->minerl) (2.8.2)\n",
            "Requirement already satisfied: serpent>=1.27 in /usr/local/lib/python3.8/dist-packages (from Pyro4>=4.76->minerl) (1.41)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->minerl) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->minerl) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->minerl) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20.0->minerl) (1.24.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->minerl) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->minerl) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytest->minerl) (1.15.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->minerl) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->minerl) (22.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->minerl) (9.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=7.5.0->minerl) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=7.5.0->minerl) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=7.5.0->minerl) (0.7.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.8/dist-packages (3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for pytorch\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m pytorch\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colabgymrender in /usr/local/lib/python3.8/dist-packages (1.1.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (from colabgymrender) (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy->colabgymrender) (4.64.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy->colabgymrender) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy->colabgymrender) (1.21.6)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy->colabgymrender) (2.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy->colabgymrender) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "EFijNdI_aETa",
        "outputId": "d13517ae-a1be-4ad6-dafa-aa443c7b8850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADmrUKxvYXGa"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8_vZpMFpiD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151f120d-71c1-4533-da3c-bcdaabec553c"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch as th\n",
        "from torch import nn\n",
        "import gym\n",
        "import minerl\n",
        "from tqdm.notebook import tqdm\n",
        "# from colabgymrender.recorder import Recorder\n",
        "from pyvirtualdisplay import Display\n",
        "from sklearn.cluster import KMeans\n",
        "import logging\n",
        "logging.disable(logging.ERROR) # reduce clutter, remove if something doesn't work to see the error logs."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKiasaipYa6l"
      },
      "source": [
        "# Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyOxGuA5At1g"
      },
      "source": [
        "class NatureCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN from DQN nature paper:\n",
        "        Mnih, Volodymyr, et al.\n",
        "        \"Human-level control through deep reinforcement learning.\"\n",
        "        Nature 518.7540 (2015): 529-533.\n",
        "\n",
        "    Nicked from stable-baselines3:\n",
        "        https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/torch_layers.py\n",
        "\n",
        "    :param input_shape: A three-item tuple telling image dimensions in (C, H, W)\n",
        "    :param output_dim: Dimensionality of the output vector\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_shape, output_dim):\n",
        "        super().__init__()\n",
        "        n_input_channels = input_shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Compute shape by doing one forward pass\n",
        "        with th.no_grad():\n",
        "            n_flatten = self.cnn(th.zeros(1, *input_shape)).shape[1]\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(n_flatten, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
        "        return self.linear(self.cnn(observations))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvrJks0gZCTW"
      },
      "source": [
        "# Setup training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpH8vzpLBGRY"
      },
      "source": [
        "def train():\n",
        "    # For demonstration purposes, we will only use ObtainPickaxe data which is smaller,\n",
        "    # but has the similar steps as ObtainDiamond in the beginning.\n",
        "    # \"VectorObf\" stands for vectorized (vector observation and action), where there is no\n",
        "    # clear mapping between original actions and the vectors (i.e. you need to learn it)\n",
        "    data = minerl.data.make(\"MineRLObtainIronPickaxeVectorObf-v0\",  data_dir='data', num_workers=1)\n",
        "\n",
        "    # First, use k-means to find actions that represent most of them.\n",
        "    # This proved to be a strong approach in the MineRL 2020 competition.\n",
        "    # See the following for more analysis:\n",
        "    # https://github.com/GJuceviciute/MineRL-2020\n",
        "\n",
        "    # Go over the dataset once and collect all actions and the observations (the \"pov\" image).\n",
        "    # We do this to later on have uniform sampling of the dataset and to avoid high memory use spikes.\n",
        "    all_actions = []\n",
        "    all_pov_obs = []\n",
        "\n",
        "    print(\"Loading data\")\n",
        "    trajectory_names = data.get_trajectory_names()\n",
        "    random.shuffle(trajectory_names)\n",
        "\n",
        "    # Add trajectories to the data until we reach the required DATA_SAMPLES.\n",
        "    for trajectory_name in trajectory_names:\n",
        "        trajectory = data.load_data(trajectory_name, skip_interval=0, include_metadata=False)\n",
        "        for dataset_observation, dataset_action, _, _, _ in trajectory:\n",
        "            all_actions.append(dataset_action[\"vector\"])\n",
        "            all_pov_obs.append(dataset_observation[\"pov\"])\n",
        "        if len(all_actions) >= DATA_SAMPLES:\n",
        "            break\n",
        "\n",
        "    all_actions = np.array(all_actions)\n",
        "    all_pov_obs = np.array(all_pov_obs)\n",
        "\n",
        "    # Run k-means clustering using scikit-learn.\n",
        "    print(\"Running KMeans on the action vectors\")\n",
        "    kmeans = KMeans(n_clusters=NUM_ACTION_CENTROIDS)\n",
        "    kmeans.fit(all_actions)\n",
        "    action_centroids = kmeans.cluster_centers_\n",
        "    print(\"KMeans done\")\n",
        "\n",
        "    # Now onto behavioural cloning itself.\n",
        "    # Much like with intro track, we do behavioural cloning on the discrete actions,\n",
        "    # where we turn the original vectors into discrete choices by mapping them to the closest\n",
        "    # centroid (based on Euclidian distance).\n",
        "\n",
        "    network = NatureCNN((3, 64, 64), NUM_ACTION_CENTROIDS).cuda()\n",
        "    optimizer = th.optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    num_samples = all_actions.shape[0]\n",
        "    update_count = 0\n",
        "    losses = []\n",
        "    # We have the data loaded up already in all_actions and all_pov_obs arrays.\n",
        "    # Let's do a manual training loop\n",
        "    print(\"Training\")\n",
        "    for _ in range(EPOCHS):\n",
        "        # Randomize the order in which we go over the samples\n",
        "        epoch_indices = np.arange(num_samples)\n",
        "        np.random.shuffle(epoch_indices)\n",
        "        for batch_i in range(0, num_samples, BATCH_SIZE):\n",
        "            # NOTE: this will cut off incomplete batches from end of the random indices\n",
        "            batch_indices = epoch_indices[batch_i:batch_i + BATCH_SIZE]\n",
        "\n",
        "            # Load the inputs and preprocess\n",
        "            obs = all_pov_obs[batch_indices].astype(np.float32)\n",
        "            # Transpose observations to be channel-first (BCHW instead of BHWC)\n",
        "            obs = obs.transpose(0, 3, 1, 2)\n",
        "            # Normalize observations. Do this here to avoid using too much memory (images are uint8 by default)\n",
        "            obs /= 255.0\n",
        "\n",
        "            # Map actions to their closest centroids\n",
        "            action_vectors = all_actions[batch_indices]\n",
        "            # Use numpy broadcasting to compute the distance between all\n",
        "            # actions and centroids at once.\n",
        "            # \"None\" in indexing adds a new dimension that allows the broadcasting\n",
        "            distances = np.sum((action_vectors - action_centroids[:, None]) ** 2, axis=2)\n",
        "            # Get the index of the closest centroid to each action.\n",
        "            # This is an array of (batch_size,)\n",
        "            actions = np.argmin(distances, axis=0)\n",
        "\n",
        "            # Obtain logits of each action\n",
        "            logits = network(th.from_numpy(obs).float().cuda())\n",
        "\n",
        "            # Minimize cross-entropy with target labels.\n",
        "            # We could also compute the probability of demonstration actions and\n",
        "            # maximize them.\n",
        "            loss = loss_function(logits, th.from_numpy(actions).long().cuda())\n",
        "\n",
        "            # Standard PyTorch update\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            update_count += 1\n",
        "            losses.append(loss.item())\n",
        "            if (update_count % 1000) == 0:\n",
        "                mean_loss = sum(losses) / len(losses)\n",
        "                tqdm.write(\"Iteration {}. Loss {:<10.3f}\".format(update_count, mean_loss))\n",
        "                losses.clear()\n",
        "    print(\"Training done\")\n",
        "\n",
        "    # Save network and the centroids into separate files\n",
        "    np.save(TRAIN_KMEANS_MODEL_NAME, action_centroids)\n",
        "    th.save(network.state_dict(), TRAIN_MODEL_NAME)\n",
        "    del data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg68dO21ZsgG"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5VCVeHyqDlm"
      },
      "source": [
        "# Parameters:\n",
        "EPOCHS = 5  # how many times we train over dataset.\n",
        "LEARNING_RATE = 0.0001  # Learning rate for the neural network.\n",
        "BATCH_SIZE = 32\n",
        "NUM_ACTION_CENTROIDS = 100  # Number of KMeans centroids used to cluster the data.\n",
        "\n",
        "DATA_SAMPLES = 300000  # how many samples to use from the dataset. Impacts RAM usage\n",
        "\n",
        "TRAIN_MODEL_NAME = 'research_potato.pth'  # name to use when saving the trained agent.\n",
        "TEST_MODEL_NAME = 'research_potato.pth'  # name to use when loading the trained agent.\n",
        "TRAIN_KMEANS_MODEL_NAME = 'centroids_for_research_potato.npy'  # name to use when saving the KMeans model.\n",
        "TEST_KMEANS_MODEL_NAME = 'centroids_for_research_potato.npy'  # name to use when loading the KMeans model.\n",
        "\n",
        "TEST_EPISODES = 10  # number of episodes to test the agent for.\n",
        "MAX_TEST_EPISODE_LEN = 18000  # 18k is the default for MineRLObtainDiamondVectorObf."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lumAopy0cHBM"
      },
      "source": [
        "# Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzD13IclpD4T"
      },
      "source": [
        "minerl.data.download(directory='data', environment='MineRLObtainIronPickaxeVectorObf-v0');"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zKLHW_JcRBJ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9OKQCgz4XQk"
      },
      "source": [
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start();"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH84zVpiB19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d41696c-ec90-49e0-a759-932fd7b511c2"
      },
      "source": [
        "train()  # only need to run this once."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6892/6892 [00:00<00:00, 163996.34it/s]\n",
            "100%|██████████| 4275/4275 [00:00<00:00, 157289.16it/s]\n",
            "100%|██████████| 5214/5214 [00:00<00:00, 146782.34it/s]\n",
            "100%|██████████| 5247/5247 [00:00<00:00, 168832.71it/s]\n",
            "100%|██████████| 4181/4181 [00:00<00:00, 141412.20it/s]\n",
            "100%|██████████| 5306/5306 [00:00<00:00, 150362.32it/s]\n",
            "100%|██████████| 2754/2754 [00:00<00:00, 164003.77it/s]\n",
            "100%|██████████| 5652/5652 [00:00<00:00, 163323.25it/s]\n",
            "100%|██████████| 3042/3042 [00:00<00:00, 147255.19it/s]\n",
            "100%|██████████| 3151/3151 [00:00<00:00, 140253.76it/s]\n",
            "100%|██████████| 5714/5714 [00:00<00:00, 162497.39it/s]\n",
            "100%|██████████| 5521/5521 [00:00<00:00, 164576.61it/s]\n",
            "100%|██████████| 7291/7291 [00:00<00:00, 171627.00it/s]\n",
            "100%|██████████| 3645/3645 [00:00<00:00, 177792.95it/s]\n",
            "100%|██████████| 3827/3827 [00:00<00:00, 159684.06it/s]\n",
            "100%|██████████| 8188/8188 [00:00<00:00, 66053.81it/s]\n",
            "100%|██████████| 7992/7992 [00:00<00:00, 168672.08it/s]\n",
            "100%|██████████| 7738/7738 [00:00<00:00, 168972.30it/s]\n",
            "100%|██████████| 11143/11143 [00:00<00:00, 179856.42it/s]\n",
            "100%|██████████| 2611/2611 [00:00<00:00, 153099.04it/s]\n",
            "100%|██████████| 3235/3235 [00:00<00:00, 165729.11it/s]\n",
            "100%|██████████| 4036/4036 [00:00<00:00, 151398.87it/s]\n",
            "100%|██████████| 7744/7744 [00:00<00:00, 160577.68it/s]\n",
            "100%|██████████| 8423/8423 [00:00<00:00, 170139.53it/s]\n",
            "100%|██████████| 12611/12611 [00:00<00:00, 165579.49it/s]\n",
            "100%|██████████| 4814/4814 [00:00<00:00, 145122.86it/s]\n",
            "100%|██████████| 4035/4035 [00:00<00:00, 147303.70it/s]\n",
            "100%|██████████| 2757/2757 [00:00<00:00, 147742.99it/s]\n",
            "100%|██████████| 5335/5335 [00:00<00:00, 161977.99it/s]\n",
            "100%|██████████| 5324/5324 [00:00<00:00, 164796.90it/s]\n",
            "100%|██████████| 2676/2676 [00:00<00:00, 140010.70it/s]\n",
            "100%|██████████| 5600/5600 [00:00<00:00, 165912.75it/s]\n",
            "100%|██████████| 8067/8067 [00:00<00:00, 169156.95it/s]\n",
            "100%|██████████| 7181/7181 [00:00<00:00, 162643.49it/s]\n",
            "100%|██████████| 3213/3213 [00:00<00:00, 185593.27it/s]\n",
            "100%|██████████| 3242/3242 [00:00<00:00, 154316.80it/s]\n",
            "100%|██████████| 3339/3339 [00:00<00:00, 157754.13it/s]\n",
            "100%|██████████| 5454/5454 [00:00<00:00, 164452.95it/s]\n",
            "100%|██████████| 4351/4351 [00:00<00:00, 153820.49it/s]\n",
            "100%|██████████| 5432/5432 [00:00<00:00, 162998.63it/s]\n",
            "100%|██████████| 3916/3916 [00:00<00:00, 158917.27it/s]\n",
            "100%|██████████| 3323/3323 [00:00<00:00, 164516.49it/s]\n",
            "100%|██████████| 9641/9641 [00:00<00:00, 171411.25it/s]\n",
            "100%|██████████| 5485/5485 [00:00<00:00, 173741.13it/s]\n",
            "100%|██████████| 14869/14869 [00:00<00:00, 179890.35it/s]\n",
            "100%|██████████| 17385/17385 [00:00<00:00, 174536.78it/s]\n",
            "100%|██████████| 21124/21124 [00:00<00:00, 174040.04it/s]\n",
            "100%|██████████| 12873/12873 [00:00<00:00, 182009.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running KMeans on the action vectors\n",
            "KMeans done\n",
            "Training\n",
            "Iteration 1000. Loss 2.198     \n",
            "Iteration 2000. Loss 2.008     \n",
            "Iteration 3000. Loss 1.953     \n",
            "Iteration 4000. Loss 1.915     \n",
            "Iteration 5000. Loss 1.877     \n",
            "Iteration 6000. Loss 1.876     \n",
            "Iteration 7000. Loss 1.800     \n",
            "Iteration 8000. Loss 1.755     \n",
            "Iteration 9000. Loss 1.723     \n",
            "Iteration 10000. Loss 1.687     \n",
            "Iteration 11000. Loss 1.654     \n",
            "Iteration 12000. Loss 1.614     \n",
            "Iteration 13000. Loss 1.599     \n",
            "Iteration 14000. Loss 1.575     \n",
            "Iteration 15000. Loss 1.550     \n",
            "Iteration 16000. Loss 1.542     \n",
            "Iteration 17000. Loss 1.516     \n",
            "Iteration 18000. Loss 1.489     \n",
            "Iteration 19000. Loss 1.472     \n",
            "Iteration 20000. Loss 1.444     \n",
            "Iteration 21000. Loss 1.436     \n",
            "Iteration 22000. Loss 1.424     \n",
            "Iteration 23000. Loss 1.414     \n",
            "Iteration 24000. Loss 1.400     \n",
            "Iteration 25000. Loss 1.389     \n",
            "Iteration 26000. Loss 1.346     \n",
            "Iteration 27000. Loss 1.359     \n",
            "Iteration 28000. Loss 1.359     \n",
            "Iteration 29000. Loss 1.319     \n",
            "Iteration 30000. Loss 1.295     \n",
            "Iteration 31000. Loss 1.300     \n",
            "Iteration 32000. Loss 1.290     \n",
            "Iteration 33000. Loss 1.280     \n",
            "Iteration 34000. Loss 1.260     \n",
            "Iteration 35000. Loss 1.258     \n",
            "Iteration 36000. Loss 1.248     \n",
            "Iteration 37000. Loss 1.249     \n",
            "Iteration 38000. Loss 1.222     \n",
            "Iteration 39000. Loss 1.200     \n",
            "Iteration 40000. Loss 1.188     \n",
            "Iteration 41000. Loss 1.190     \n",
            "Iteration 42000. Loss 1.162     \n",
            "Iteration 43000. Loss 1.160     \n",
            "Iteration 44000. Loss 1.178     \n",
            "Iteration 45000. Loss 1.149     \n",
            "Iteration 46000. Loss 1.155     \n",
            "Iteration 47000. Loss 1.157     \n",
            "Training done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_6j2-ibcxZh"
      },
      "source": [
        "# Start Minecraft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja8WN5rgc3Ex"
      },
      "source": [
        "env = gym.make('MineRLObtainDiamondVectorObf-v0')\n",
        "# env = Recorder(env, './video', fps=60)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjKpJgZicn6L"
      },
      "source": [
        "# Run your agent\n",
        "As the code below runs you should see episode videos and rewards show up. You can run the below cell multiple times to see different episodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQeH2QgcjpK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0147462-3f1c-4a88-cb21-7193db61f34f"
      },
      "source": [
        "from time import time\n",
        "action_centroids = np.load(TEST_KMEANS_MODEL_NAME)\n",
        "network = NatureCNN((3, 64, 64), NUM_ACTION_CENTROIDS).cuda()\n",
        "network.load_state_dict(th.load(TEST_MODEL_NAME))\n",
        "\n",
        "stats = {'runtime': [], 'reward': []}\n",
        "num_actions = action_centroids.shape[0]\n",
        "action_list = np.arange(num_actions)\n",
        "\n",
        "for episode in range(TEST_EPISODES):\n",
        "    start = time()\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "\n",
        "    while not done:\n",
        "        # Process the action:\n",
        "        #   - Add/remove batch dimensions\n",
        "        #   - Transpose image (needs to be channels-last)\n",
        "        #   - Normalize image\n",
        "        obs = th.from_numpy(obs['pov'].transpose(2, 0, 1)[None].astype(np.float32) / 255).cuda()\n",
        "        # Turn logits into probabilities\n",
        "        probabilities = th.softmax(network(obs), dim=1)[0]\n",
        "        # Into numpy\n",
        "        probabilities = probabilities.detach().cpu().numpy()\n",
        "        # Sample action according to the probabilities\n",
        "        discrete_action = np.random.choice(action_list, p=probabilities)\n",
        "\n",
        "        # Map the discrete action to the corresponding action centroid (vector)\n",
        "        action = action_centroids[discrete_action]\n",
        "        minerl_action = {\"vector\": action}\n",
        "\n",
        "        obs, reward, done, info = env.step(minerl_action)\n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        if steps >= MAX_TEST_EPISODE_LEN:\n",
        "            break\n",
        "\n",
        "    stats['runtime'].append(time() - start)\n",
        "    stats['reward'].append(total_reward)\n",
        "\n",
        "    # env.release()\n",
        "    # env.play()\n",
        "    print(f'Episode #{episode + 1} reward: {total_reward}\\t\\t episode length: {steps}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode #1 reward: 0.0\t\t episode length: 1233\n",
            "\n",
            "Episode #2 reward: 0.0\t\t episode length: 4645\n",
            "\n",
            "Episode #3 reward: 0.0\t\t episode length: 2918\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('stats_BC.json', 'w') as outfile:\n",
        "    json.dump(stats, outfile)"
      ],
      "metadata": {
        "id": "FW7_NoFIDfJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}